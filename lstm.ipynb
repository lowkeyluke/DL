{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-series Classification & Prediction w/ LSTM models\n",
    "\n",
    "NOTE: Some cells will not run properly as I have removed some snippets of private code that is not shared here. If you wish to see my full notebook, you are more than welcome to ask me for it.\n",
    "\n",
    "\n",
    "Given data in timesteps, predict a future timestep. \n",
    "\n",
    "#### Data hyperparameters:\n",
    "- timestep_length: each data point is a summation of data of the timestep length\n",
    "- seq_len: # of timesteps observed before making a prediction\n",
    "##### Dependent parameters (changing the hyperparameters will change these parameters accordingly):\n",
    "- target/prediction_timestep: (how far into the future you want to predict) # of timesteps from the last observed timestep\n",
    "- batch_size: # of sequences\n",
    "\n",
    "#### LSTM hyperparameters:\n",
    "- input_size: # of features in each data point\n",
    "- hidden_size: # of nodes in hidden layer\n",
    "- num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T03:20:31.289978Z",
     "start_time": "2020-02-05T03:20:30.079013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import indicators\n",
    "'''\n",
    "import math\n",
    "import requests\n",
    "import datetime\n",
    "import csv\n",
    "import time\n",
    "from operator import itemgetter\n",
    "'''\n",
    "\n",
    "device = torch.device(torch.cuda.current_device() if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T03:25:50.652560Z",
     "start_time": "2020-02-05T03:25:50.641568Z"
    }
   },
   "outputs": [],
   "source": [
    "class LstmModel(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers=1, dropout_rate=.1):\n",
    "        super(LstmModel, self).__init__()\n",
    "        # Hyperparams\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_classes = 2  # Binary Classification\n",
    "        # Model\n",
    "        self.rnn = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=self.num_layers,\n",
    "                          dropout=self.dropout_rate)\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        self.fc_out = nn.Linear(self.hidden_size, self.num_classes)  # Output layer (FC)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, inputs, hidden_state):\n",
    "        # init\n",
    "        batch_size = int(inputs.size(1))\n",
    "        \n",
    "        outputs, hidden_state = self.rnn(inputs, hidden_state)\n",
    "        # Take last output only (many-to-one)\n",
    "        last_output = outputs[-1].view(1, batch_size, -1)\n",
    "        \n",
    "        last_output = self.dropout(last_output)\n",
    "        last_output = self.fc_out(last_output)\n",
    "        last_output = self.softmax(last_output).view(batch_size, self.num_classes)\n",
    "        \n",
    "        return last_output, hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM-FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T04:16:19.670583Z",
     "start_time": "2020-02-05T04:16:19.644535Z"
    }
   },
   "outputs": [],
   "source": [
    "class LstmFCN(nn.Module):\n",
    "    def __init__(self, hidden_size=128, num_layers=1, dropout_rate=.8, dimension_shuffle=False):\n",
    "        super(LstmFCN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dimension_shuffle = dimension_shuffle\n",
    "        self.out_features = 128\n",
    "        self.kernel_sizes = [8, 5, 3]\n",
    "        self.num_classes = 2\n",
    "        # Model\n",
    "        if dimension_shuffle:\n",
    "            self.rnn = nn.LSTM(input_size=sequence_len, hidden_size=self.hidden_size, num_layers=self.num_layers)\n",
    "        else:\n",
    "            self.rnn = nn.LSTM(input_size=input_size, hidden_size=self.hidden_size, num_layers=self.num_layers)\n",
    "            #                   , dropout=self.dropout_rate)  # obsolete with single layer\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        # FCN (Conv)\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=128, kernel_size=self.kernel_sizes[0])\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=self.kernel_sizes[1])\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        # relu\n",
    "        self.conv3 = nn.Conv1d(256, self.out_features, kernel_size=kernel_sizes[2])\n",
    "        self.bn3 = nn.BatchNorm1d(self.out_features)\n",
    "        # self.pool = nn.AvgPool1d()  # done below due to variable sequence_len\n",
    "        # Concatenate LSTM+FCN\n",
    "        # lstm_fcn concat shape: dim1: [7 x 256 x 1]  # dim0: [14 x 128 x 1], dim2: [7 x 128 x 2]\n",
    "        self.calc_concat_size = self.out_features + self.hidden_size\n",
    "        # evaluate all returned features from both nets, & produce a label/classification\n",
    "        self.fc_out = nn.Linear(self.calc_concat_size, self.num_classes)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, inputs, hidden_state):\n",
    "        # init\n",
    "        # inputs: [seq_len, batch_size, input_size]\n",
    "        batch_size = int(inputs.size(1))\n",
    "        seq_len = int(inputs.size(0))  # timesteps\n",
    "        input_size = int(inputs.size(2))  # num_variables\n",
    "        bn = nn.BatchNorm1d(batch_size).cuda()  # for varying batch sizes.\n",
    "        \n",
    "        ''' inputs -> both LSTM & FCN separately, then concatenate '''\n",
    "        # inputs -> LSTM\n",
    "        # LSTM takes inputs of [seq_len, batch_size, input_size] (if shuffle: [input_size, batch_size, seq_len])\n",
    "        if self.dimension_shuffle:\n",
    "            inputs = inputs.reshape(input_size, batch_size, seq_len)\n",
    "        lstm_outputs, hidden_state = self.rnn(inputs, hidden_state)\n",
    "        # If many-to-one: Take last output only\n",
    "        lstm_outputs = lstm_outputs[-1].view(1, batch_size, -1)  # fixme? comment out if many-to-many\n",
    "        lstm_outputs = self.dropout(lstm_outputs)\n",
    "        # LSTM outputs: [seq_len, batch_size, hidden_size] (if shuffle: [input_size, batch_size, hidden_size])\n",
    "        # if many-to-one: [1, batch_size, hidden_size]\n",
    "        \n",
    "        # inputs -> FCN\n",
    "        # FCN takes inputs of [batch_size, input_size, seq_len]\n",
    "        inputs = inputs.reshape(batch_size, input_size, seq_len)\n",
    "        outputs = self.conv1(inputs)\n",
    "        outputs = self.bn1(outputs)\n",
    "        outputs = self.relu(outputs)\n",
    "        outputs = self.conv2(outputs)\n",
    "        outputs = self.bn2(outputs)\n",
    "        outputs = self.relu(outputs)\n",
    "        outputs = self.conv3(outputs)\n",
    "        outputs = self.bn2(outputs)\n",
    "        fcn_outputs = self.relu(outputs)\n",
    "        # [batch_size, self.out_features, fcn_out_size]  # [batch_size, 128, 51]\n",
    "        \n",
    "        # Global Average Pooling (helps minimize overfitting): takes average of entire sequence (dimensionality reduction)\n",
    "        # calculate fcn_out_size (due to variable sequence length)\n",
    "        fcn_out_size = seq_len - sum(self.kernel_sizes) + len(self.kernel_sizes)  # 64 - (8+5+3) + 3\n",
    "        pool = nn.AvgPool1d(fcn_out_size)\n",
    "        fcn_outputs = pool(fcn_outputs)\n",
    "        # FCN outputs: [batch_size, self.out_features, 1]\n",
    "        \n",
    "        ''' Concatenate LSTM+FCN '''\n",
    "        # Sizes of tensors must match except in chosen dimension. (default=0)\n",
    "        # Must reshape atleast 1 of the tensors\n",
    "        lstm_outputs = lstm_outputs.view(batch_size, -1, 1)  # [batch_size, hidden_size, 1]\n",
    "        # Concat dim=1 (out_features from each net). \"adding\" features from lstm+fcn together, for each sample\n",
    "        lstm_fcn_outputs = torch.cat([lstm_outputs, fcn_outputs], dim=1)\n",
    "        # lstm_fcn concat shape: [batch_size, self.out_features + self.hidden_size, 1]\n",
    "        \n",
    "        # Linear\n",
    "        lstm_fcn_outputs = lstm_fcn_outputs.squeeze(2)  # [batch_size, features]\n",
    "        lstm_fcn_outputs = self.fc_out(lstm_fcn_outputs)\n",
    "        lstm_fcn_outputs = self.softmax(lstm_fcn_outputs)\n",
    "        # LSTM-FCN outputs: [batch_size, num_classes]\n",
    "        \n",
    "        return lstm_fcn_outputs, hidden_state  # passing hidden_state is obsolete, only done for compatibility w other model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Raw Data\n",
    "\n",
    "- Stock quotes [timestep, price, volume], from CryptoCompare API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 128  # hyperparam\n",
    "api_crypto = 'https://min-api.cryptocompare.com/data/v2/'\n",
    "timestep_length = 'minute'  # 'hour', 'day'\n",
    "coin = 'BTC'\n",
    "url_crypto = api_crypto + 'histo' + timestep_length + '?fsym=' + coin + '&tsym=USD' + '&limit=2000'\n",
    "\n",
    "''' Get Data (in increments of 2000) '''\n",
    "# raw format: \n",
    "raw_field_headers = ['time', 'high', 'low', 'open', 'volumefrom', 'volumeto', 'close']  # , 'conf', 'cont']\n",
    "field_headers = raw_field_headers  # define desired fields & order\n",
    "crypto_quotes = []\n",
    "\n",
    "queries = 5  # Set how many increments  # 2,000 * 5 = 10,000\n",
    "timestamp = None  # needed to call additional queries\n",
    "url = url_crypto\n",
    "for i in range(queries):\n",
    "    query = []\n",
    "    if timestamp:\n",
    "        url = url_crypto + '&toTs=' + str(timestamp)\n",
    "    response = requests.get(url)\n",
    "    raw_quotes = response.json()['Data']['Data']  # json\n",
    "    timestamp = raw_quotes[0]['time']\n",
    "    \n",
    "    for quote in raw_quotes:\n",
    "        desired_quote = []\n",
    "        for field in field_headers:\n",
    "            desired_quote.append(quote[field])\n",
    "        query.append(desired_quote)\n",
    "    query.reverse()\n",
    "    if crypto_quotes:  # ADDITIONAL QUERIES\n",
    "        if query[0] == crypto_quotes[-1]:\n",
    "            del query[0]\n",
    "            # print(\"deleted repeated timestamp\")\n",
    "        crypto_quotes.extend(query)\n",
    "    else:  # 1ST QUERY\n",
    "        crypto_quotes = query\n",
    "    del raw_quotes\n",
    "print(crypto_quotes[:2], crypto_quotes[-2:])\n",
    "\n",
    "''' Modify data '''\n",
    "# chronological order\n",
    "crypto_quotes.reverse()\n",
    "\n",
    "# TODO\n",
    "''' ADD PERSONAL 'indicators.py' file to GitHub\n",
    "# INDICATORS\n",
    "crypto_quotes = indicators.atr(crypto_quotes, period=period, closeCol=6, lowCol=2, highCol=1)  # period hyperparam\n",
    "crypto_quotes = indicators.rsi(crypto_quotes, period=period, close=6)\n",
    "crypto_quotes = indicators.aggregate(crypto_quotes, period=period, lowCol=2, highCol=1)\n",
    "field_headers.append('atr')\n",
    "field_headers.append('rsi')\n",
    "field_headers.append('agg_high')\n",
    "field_headers.append('agg_low')\n",
    "'''\n",
    "\n",
    "for i in range(len(crypto_quotes)):\n",
    "    # print datetime timestamp of first & last quotes (to verify order)\n",
    "    if i < 2 or i > len(crypto_quotes)-2:\n",
    "        crypto_quotes[i][0] = str(datetime.datetime.fromtimestamp(crypto_quotes[i][0]))  # convert to datetime timestamp\n",
    "        print(crypto_quotes[i])\n",
    "    # Move close_price to end of list\n",
    "    crypto_quotes[i].append(crypto_quotes[i][6])  # add to end\n",
    "    del crypto_quotes[i][6]  # del original spot (close)\n",
    "    # del crypto_quotes[i][0]  # del timestamp\n",
    "    crypto_quotes[i][0] = crypto_quotes[i][3]  # replace timestamp with open_price\n",
    "    del crypto_quotes[i][3]  # del original spot (open)\n",
    "    ''' Add (2) spots for features that will be added later '''  # observed classes 0 & 1\n",
    "    crypto_quotes[i].insert(0, 0)\n",
    "    crypto_quotes[i].insert(0, 0)\n",
    "    # TODO: Add more\n",
    "    # crypto_quotes[i].insert(0, 0)\n",
    "    # crypto_quotes[i].insert(0, 0)\n",
    "    \n",
    "# modify corresponding field headers\n",
    "field_headers.append('close')\n",
    "del field_headers[6]\n",
    "field_headers[0] = field_headers[3]\n",
    "del field_headers[3]\n",
    "field_headers.insert(0, 'PRIVATE_CODE0')  # private repo: feel free to ask me to see it\n",
    "field_headers.insert(1, 'PRIVATE_CODE1')\n",
    "field_headers[5] = 'vol_from'  # shorthand 'volumefrom'\n",
    "field_headers[6] = 'vol_to'\n",
    "\n",
    "# delete first quotes w/ missing indicator values\n",
    "del crypto_quotes[:period+1]\n",
    "mod = len(crypto_quotes) % 10  # make divisible by 10\n",
    "if mod > 0: del crypto_quotes[:mod]\n",
    "\n",
    "print(crypto_quotes[-1])\n",
    "features = {}\n",
    "features_i = {}\n",
    "for i in range(len(field_headers)):\n",
    "    features_i[i] = field_headers[i]  # int: 'string'\n",
    "    features[field_headers[i]] = i  # 'string': int\n",
    "print(features)\n",
    "print(\"# of quotes:\", len(crypto_quotes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Verify data (Plot/print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "quotes = np.asarray(crypto_quotes)\n",
    "# full dataset: ~10,000 (~= 7 days)  # 1 day = 1440\n",
    "slice_from = -9000  # -9000\n",
    "slice_to = -1  # -1\n",
    "\n",
    "plt.plot(quotes[slice_from:slice_to, -1])\n",
    "plt.title('close_price')\n",
    "plt.show()\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(quotes[slice_from:slice_to, 3])\n",
    "plt.title('high, low')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(quotes[slice_from:slice_to, 4])\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(quotes[slice_from:slice_to, features['vol_from']])\n",
    "plt.title('vol_from, vol_to')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(quotes[slice_from:slice_to, features['vol_to']])\n",
    "plt.show()\n",
    "scaler = MinMaxScaler()\n",
    "vols = scaler.fit_transform(quotes[slice_from:slice_to, 5:7])\n",
    "plt.plot(vols[:, 0])\n",
    "plt.plot(vols[:, 1])\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(quotes[slice_from:slice_to, features['atr']])\n",
    "plt.title('atr, rsi')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(quotes[slice_from:slice_to, features['rsi']])\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(quotes[slice_from:slice_to, features['agg_high']])\n",
    "plt.title('Aggregate high, low')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(quotes[slice_from:slice_to, features['agg_low']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = np.asarray(crypto_quotes)\n",
    "unscaled_quotes = quotes\n",
    "''' Feature Normalization/Scaling '''\n",
    "# Linearly transform x to y= (x-min)/(max-min)\n",
    "# quotes = signal.detrend(quotes)\n",
    "scaler = MinMaxScaler()  # normalize inputs (price,vol) 0-1 => min-max (low-high)\n",
    "quotes[:, 5:9] = scaler.fit_transform(quotes[:, 5:9])\n",
    "print(\"features 5-8 normalized:\")\n",
    "print(quotes[-1])\n",
    "min_price = min(quotes[:, features['low']])\n",
    "max_price = max(quotes[:, features['high']])\n",
    "print(\"min, max prices:\", min_price, max_price)\n",
    "for i in range(len(quotes)):\n",
    "    quotes[i][features['open']] = (quotes[i][features['open']] - min_price) / (max_price - min_price)\n",
    "    quotes[i][features['high']] = (quotes[i][features['high']] - min_price) / (max_price - min_price)\n",
    "    quotes[i][features['low']] = (quotes[i][features['low']] - min_price) / (max_price - min_price)\n",
    "    quotes[i][features['close']] = (quotes[i][features['close']] - min_price) / (max_price - min_price)\n",
    "    quotes[i][features['agg_high']] = (quotes[i][features['agg_high']] - min_price) / (max_price - min_price)\n",
    "    quotes[i][features['agg_low']] = (quotes[i][features['agg_low']] - min_price) / (max_price - min_price)\n",
    "print(\"all prices normalized:\")\n",
    "print(quotes[-1])\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "target = 8  # 2,4,8  # how far into the future to predict\n",
    "percent_change = .001\n",
    "sequence_len = 64\n",
    "short_sequence_len = 24  # 16\n",
    "average_of = 1024  # 256  # 512, 1024  # PRIVATE\n",
    "input_size = len(quotes[0])\n",
    "print(\"input_size:\", input_size)\n",
    "test_size = 1000  # Set size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' sequence data\n",
    "Group the data into contiguous sequences of sequence_length. (and classify, and get last/live sequence)\n",
    "Input: quotes\n",
    "Output: \n",
    "- sequenced_data, labels\n",
    "- PRIVATE_CODE0, PRIVATE_CODE1\n",
    "'''\n",
    "private_quote_sequences = []  # train\n",
    "private_labels = []\n",
    "all_quote_sequences = []  # test\n",
    "test_labels = []\n",
    "populating_test = False\n",
    "unscaled_quote_sequences = []\n",
    "# private\n",
    "private_code0 = []\n",
    "private_code1 = []\n",
    "private_min = []\n",
    "private_max = []\n",
    "close = -1  # close_price column\n",
    "\n",
    "sequence = []\n",
    "last_sequence = []\n",
    "for t in range(sequence_len, len(quotes)):  # fixme?\n",
    "    sequence = quotes[t - sequence_len: t]\n",
    "    unscaled_sequence = unscaled_quotes[t - sequence_len: t]\n",
    "\n",
    "    ''' Define labels/classes (price action) '''\n",
    "    last_observed_timestep = sequence[-1][close]  # sequence[-1] == quotes[t-1]\n",
    "    try:\n",
    "        ''' Train labels '''\n",
    "        prediction_timestep = quotes[t+sequence_len+target, close]\n",
    "        ''' PRIVATE\n",
    "        # prediction_timeframe = quotes[ ... private code ... ]  # # set timeframe=1 for prediction_timestep = quotes[t+seq_len+target, close]\n",
    "        timeframe_labels = []\n",
    "        # Characterize timeframe by ... private ... at ... private ... timestep\n",
    "        for quote in prediction_timeframe:\n",
    "            if quote < last_observed_timestep - (last_observed_timestep * percent_change):  # default: pct_change = 0\n",
    "                ... private ...\n",
    "            elif quote > ... private ... :\n",
    "                ... private ...\n",
    "            else:  # doesn't fall into criteria. will be filtered/skipped\n",
    "                timeframe_labels.append(None)\n",
    "        # Filtering\n",
    "        # PRIVATE_CODE\n",
    "        '''\n",
    "        if prediction_timestep < last_observed_timestep:\n",
    "            label = 0\n",
    "        elif prediction_timestep > last_observed_timestep:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = -1\n",
    "        if t%512==0: print(t, \":\", label)\n",
    "            \n",
    "        ''' Test labels (may vary from Train) '''\n",
    "        # PRIVATE_CODE\n",
    "        if t >= (len(quotes) - test_size):  # Train set fully populated  # NOTE: modified/private\n",
    "            populating_test = True\n",
    "            if t > len(quotes) - test_size:\n",
    "                if label >= 0:\n",
    "                    all_quote_sequences.append(sequence)\n",
    "                    test_labels.append(label)\n",
    "                    unscaled_quote_sequences.append(unscaled_sequence)\n",
    "                else:  # label == -1. Test set will not exclude any sequence\n",
    "                    test_prediction_timeframe = quotes[t: (t - 1) + target, close]  # modified/private\n",
    "                    test0 = False\n",
    "                    test1 = False\n",
    "                    for quote in test_prediction_timeframe:\n",
    "                        if quote < last_observed_timestep:\n",
    "                            test0 = True\n",
    "                        elif quote > last_observed_timestep:\n",
    "                            test1 = True\n",
    "                    if test0 and test1:\n",
    "                        test_labels.append(-1)\n",
    "                    elif test0:\n",
    "                        test_labels.append(0)\n",
    "                    elif test1:\n",
    "                        test_labels.append(1)\n",
    "                    else:\n",
    "                        test_labels.append(-1)\n",
    "                    all_quote_sequences.append(sequence)\n",
    "                    unscaled_quote_sequences.append(unscaled_sequence)\n",
    "        else:  # Populate Train\n",
    "            if label < 0:  # <  # <= for \"unary\" classification (buy)\n",
    "                continue  # label -1 skipped (undesirable training data)\n",
    "                # label = 0\n",
    "            private_quote_sequences.append(sequence)\n",
    "            private_labels.append(label)\n",
    "            # PRIVATE_CODE.append(...private...)\n",
    "            \n",
    "        # If you are here, a label has been appended to Train or Test within this loop\n",
    "        \n",
    "        ''' CALCULATE ... PRIVATE ... OF DEFINED CLASSES'''\n",
    "        # PRIVATE_CODE\n",
    "        \n",
    "        \n",
    "print(\"num sequences:\", len(private_quote_sequences))\n",
    "num_class0 = private_labels.count(0)\n",
    "num_class1 = private_labels.count(1)\n",
    "print(\"num_class0:\", num_class0)\n",
    "print(\"num_class1:\", num_class1)\n",
    "''' class_weights if class imbalance? '''\n",
    "nominator = min(num_class0, num_class1)\n",
    "class0_weight = nominator / num_class0\n",
    "class1_weight = nominator / num_class1\n",
    "class_weights = torch.Tensor([class0_weight, class1_weight]).to(device)\n",
    "print(\"class_weights:\", class_weights)\n",
    "\n",
    "print(\"num sequences (test):\", len(all_quote_sequences))\n",
    "print('\"classless\":', test_labels.count(-1))\n",
    "test_data = np.asarray(all_quote_sequences)\n",
    "test_labels = np.asarray(test_labels)\n",
    "print(test_data[-1][-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)\n",
    "Private code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Initialize model(s) '''\n",
    "fcn = False\n",
    "ensemble = False\n",
    "\n",
    "if fcn:\n",
    "    hidden_size = 128\n",
    "    num_layers = 2  # 1\n",
    "    dropout_rate = .8  # .6\n",
    "    # weight_decay = 1e-3  # 1e-6\n",
    "    lr_init = 1e-3  # default Adam lr=1e-3\n",
    "    lr = lr_init\n",
    "    model = LstmFCN(hidden_size=hidden_size, num_layers=num_layers, dropout_rate=dropout_rate, dimension_shuffle=False)\n",
    "else:\n",
    "    hidden_size = 256  # 128\n",
    "    num_layers = 3  # 2-4\n",
    "    # num_layers_fc = 1  # 0 still has 1 linear output layer\n",
    "    dropout_rate = .8  # .1, .6\n",
    "    # weight_decay = 1e-3  # 1e-3, 5e-4, 1e-4, 1e-5\n",
    "    lr_init = 1e-3  # 5e-3\n",
    "    lr = lr_init\n",
    "    model = LstmModel(hidden_size, num_layers, dropout_rate)  # , num_layers_fc, batch_size) \n",
    "\n",
    "model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()  # weight=class_weights)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), weight_decay=weight_decay, lr=lr)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)  # TODO: warm restart\n",
    "hidden_state = None\n",
    "\n",
    "if ensemble:\n",
    "    # short_sequence_len = 16  # must be init during data generation\n",
    "    hidden_size2 = 256  # 128\n",
    "    num_layers2 = 3  # 1-2\n",
    "    # num_layers_fc2 = 0  # 0 still has 1 linear output layer\n",
    "    dropout_rate2 = .8\n",
    "    # weight_decay2 = 1e-3\n",
    "    # lr = 1e-3\n",
    "    model2 = LstmModel(hidden_size2, num_layers2, dropout_rate2)  # , num_layers_fc2, batch_size)\n",
    "    model2.to(device)\n",
    "    # optimizer2 = torch.optim.Adam(model2.parameters(), weight_decay=weight_decay2, lr=lr2)\n",
    "    optimizer2 = torch.optim.AdamW(model2.parameters(), lr=lr)\n",
    "    hidden_state2 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### LR Range Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "''' LR Range Test '''\n",
    "lr_test = 1e-7\n",
    "# init temporary \"test\" model_tests\n",
    "model_test = model\n",
    "optimizer_test = torch.optim.Adam(model_test.parameters(), lr=lr_test)\n",
    "if ensemble: \n",
    "    model_test2 = model2\n",
    "    optimizer_test2 = torch.optim.Adam(model_test2.parameters(), lr=lr_test)\n",
    "    \n",
    "lrs = []\n",
    "losses = []\n",
    "losses2 = []\n",
    "batch_size = 1\n",
    "train_sequences = np.asarray(private_quote_sequences)  # todo: all_quote_sequences\n",
    "train_labels = np.asarray(private_labels)\n",
    "for i in range(len(train_sequences)):\n",
    "    hidden_state = None  # \"stateless\": init before every batch. \"stateful\": retain hidden state\n",
    "    sequence_batch = torch.from_numpy(train_sequences[i:i+batch_size]).float().view(sequence_len, batch_size, input_size).to(device)  # TODO: [0:i]\n",
    "    label_batch = torch.from_numpy(train_labels[i:i+batch_size]).long().to(device)\n",
    "    \n",
    "    optimizer_test.zero_grad()\n",
    "    outputs, hidden_state = model_test(sequence_batch, hidden_state)  # batch[:, :-1, :]\n",
    "    loss = loss_function(outputs, label_batch)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer_test.step()\n",
    "    if ensemble:\n",
    "        hidden_state2 = None  # ensemble\n",
    "        optimizer_test2.zero_grad()\n",
    "        outputs2, hidden_state2 = model_test2(sequence_batch[-short_sequence_len:, :, :], hidden_state2)  # ensemble\n",
    "        loss2 = loss_function(outputs2, label_batch)  # ensemble\n",
    "        #\n",
    "        loss2.backward(retain_graph=True)\n",
    "        optimizer_test2.step()\n",
    "    \n",
    "    lrs.append(round(lr_test,6))\n",
    "    losses.append(round(float(loss.data),4))\n",
    "    if ensemble: losses2.append(round(float(loss2.data),4))\n",
    "    lr_test *= 1.25\n",
    "    optimizer_test = torch.optim.Adam(model_test.parameters(), lr=lr_test)\n",
    "    if ensemble: optimizer_test2 = torch.optim.Adam(model_test2.parameters(), lr=lr_test)\n",
    "    if lr_test >= .1:\n",
    "        break\n",
    "del lr_test, model_test, optimizer_test, hidden_state\n",
    "if ensemble: del model_test2, optimizer_test2, hidden_state2\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "if ensemble:\n",
    "    plt.plot(losses2)\n",
    "    plt.title('model2')\n",
    "    plt.show()\n",
    "    \n",
    "# print(lr_plot[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "w/ LOOCV Test integrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Train '''\n",
    "batch_size = 1\n",
    "batch_num = 0\n",
    "eval_every = 40  # 40, 80\n",
    "predictions_vs_labels = []\n",
    "loocv = []\n",
    "# plot_sequence = []\n",
    "pred_vs_lab1 = []\n",
    "pred_vs_lab2 = []  # ensemble\n",
    "max_preds = []\n",
    "max_preds2 = []  # ensemble\n",
    "ensemble_weak = []  # ensemble\n",
    "batch_num_restart = 0\n",
    "lr_restart = 0\n",
    "# for data_batch, labels_batch in zip(train_data, train_labels):\n",
    "train_sequences = np.asarray(private_quote_sequences)  # todo: all_quote_sequences\n",
    "train_labels = np.asarray(private_labels)\n",
    "for i in range(len(train_sequences) - batch_size - 1):\n",
    "    hidden_state = None  # \"stateless\": init before every batch. \"stateful\": retain hidden state\n",
    "    sequence_batch = torch.from_numpy(train_sequences\n",
    "                                      [i:i+batch_size]).float().view(sequence_len, \n",
    "                                                                     batch_size, input_size).to(device)  # TODO: [0:i]\n",
    "    label_batch = torch.from_numpy(train_labels[i:i+batch_size]).long().to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs, hidden_state = model(sequence_batch, hidden_state)  # batch[:, :-1, :]\n",
    "    loss = loss_function(outputs, label_batch)\n",
    "    if ensemble:\n",
    "        hidden_state2 = None  # ensemble\n",
    "        optimizer2.zero_grad()\n",
    "        outputs2, hidden_state2 = model2(sequence_batch[-short_sequence_len:, :, :], hidden_state2)  # ensemble\n",
    "        loss2 = loss_function(outputs2, label_batch)  # ensemble\n",
    "    # Backprop\n",
    "    try:\n",
    "        loss.backward(retain_graph=True)\n",
    "        if ensemble: loss2.backward(retain_graph=True)  # ensemble\n",
    "    except RuntimeError:  # memory issue\n",
    "        loss.backward()  # last backprop\n",
    "        if ensemble: loss2.backward()  # ensemble\n",
    "        # del sequence_batch, label_batch, outputs, loss\n",
    "        torch.cuda.empty_cache()\n",
    "        break  # end training (early)\n",
    "    optimizer.step()\n",
    "    if ensemble: optimizer2.step()  # ensemble\n",
    "    \n",
    "    batch_num += 1\n",
    "    batch_num_restart += 1\n",
    "    lr_restart += 1\n",
    "    ''' LOOCV (Test) '''\n",
    "    if batch_num_restart >= eval_every:\n",
    "        hidden_state_test = None\n",
    "        loocv_sequence = torch.from_numpy(train_sequences[i+batch_size]).float().view(sequence_len, 1, input_size).to(device)\n",
    "        prediction, hidden_state_test = model(loocv_sequence, hidden_state_test)  # batch[:, -1, :]\n",
    "        label = train_labels[i+batch_size]  # label_batch[-1]\n",
    "        # loss = loss_function(prediction, label)\n",
    "        if ensemble:\n",
    "            hidden_state_test2 = None  # ensemble\n",
    "            prediction2, hidden_state_test2 = model2(loocv_sequence[-short_sequence_len:, :, :], hidden_state_test2)  # batch[-short_seq_len:, -1, :]\n",
    "        del loocv_sequence\n",
    "        \n",
    "        ''' Eval '''\n",
    "        prediction = list(prediction.data.squeeze())\n",
    "        max_prediction = float(max(prediction))\n",
    "        prediction = prediction.index(max(prediction))\n",
    "        \n",
    "        selective_guard = False\n",
    "        max_preds.append(max_prediction)\n",
    "        avg_max = sum(max_preds) / len(max_preds)\n",
    "        if not ensemble:\n",
    "            selective_guard = max_prediction >= avg_max\n",
    "        else:  # ensemble\n",
    "            prediction2 = list(prediction2.data.squeeze())\n",
    "            max_prediction2 = float(max(prediction2))\n",
    "            prediction2 = prediction2.index(max(prediction2))\n",
    "            max_preds2.append(max_prediction2)\n",
    "            avg_max2 = sum(max_preds2) / len(max_preds2)\n",
    "            selective_guard = prediction == prediction2   # and max_prediction >= avg_max and max_prediction2 >= avg_max2\n",
    "            \n",
    "        # selective_guard = True  # COMMENT OUT IF YOU WANT TO FILTER OUT SOME PREDICTIONS. True will eval every prediction\n",
    "        if selective_guard:  # if deemed worthy prediction\n",
    "            predictions_vs_labels.append([prediction, label])  # then save for evaluation\n",
    "            # Evaluate + Print to console after collecting certain #of predictions\n",
    "            if len(predictions_vs_labels) % eval_every == 0:\n",
    "                print(\"Batch\", batch_num, \"(\", batch_num_restart, \")\")\n",
    "                print(\"loss:\", round(float(loss.data),4))\n",
    "                accuracy = (predictions_vs_labels.count([0,0]) \n",
    "                            + predictions_vs_labels.count([1,1])) / len(predictions_vs_labels)\n",
    "                accuracy_last_eval = (predictions_vs_labels[-eval_every:].count([0,0]) \n",
    "                                   + predictions_vs_labels[-eval_every:].count([1,1])) / eval_every\n",
    "                print(\"accuracy:\", round(accuracy,4), \"(last\", eval_every, \":\", accuracy_last_eval, \")\")\n",
    "                loocv.append(accuracy)\n",
    "                \n",
    "                if accuracy_last_eval < .6 and lr_restart >= len(train_sequences)//16:\n",
    "                    if lr > 3e-4:\n",
    "                        lr *= (1/math.sqrt(2))\n",
    "                    if lr < 3e-4:\n",
    "                        lr = 3e-4\n",
    "                    if batch_num_restart >= len(train_sequences)//4:  # WARM RESTART\n",
    "                        lr_init /= 1.1\n",
    "                        lr = lr_init  # 1e-3\n",
    "                        batch_num_restart = 0\n",
    "                    print(\"lr =>\", round(lr,6))\n",
    "                    # optimizer = torch.optim.Adam(model.parameters(), weight_decay=weight_decay, lr=lr)\n",
    "                    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "                    if ensemble: optimizer2 = torch.optim.AdamW(model2.parameters(), lr=lr)\n",
    "                    lr_restart = 0\n",
    "                \n",
    "                restart = False  # change to True if want to restart model if performance suddenly falls steeply\n",
    "                # e.g. overfit, ... private ...\n",
    "                if restart:\n",
    "                    if accuracy_last_eval < .4:  # .4, .45, .5\n",
    "                        print(\"restarting model(s)\")\n",
    "                        batch_num_restart = 0\n",
    "                        # del model, loss_function, optimizer\n",
    "                        if fcn:\n",
    "                            model = LstmFCN(hidden_size, num_layers, dropout_rate)\n",
    "                        else:\n",
    "                            model = LstmModel(hidden_size, num_layers, num_layers_fc, dropout_rate)\n",
    "                        model.to(device)\n",
    "                        loss_function = nn.CrossEntropyLoss()  # weight=class_weights)\n",
    "                        optimizer = torch.optim.Adam(model.parameters(), weight_decay=weight_decay)  # , lr=lr)\n",
    "                        if ensemble:\n",
    "                            # del model2, optimizer2\n",
    "                            # short_sequence_len = 16\n",
    "                            model2 = LstmModel(hidden_size, num_layers, num_layers_fc, dropout_rate)\n",
    "                            model2.to(device)\n",
    "                            optimizer2 = torch.optim.Adam(model2.parameters(), weight_decay=weight_decay, lr=lr2)\n",
    "        else:\n",
    "            pred_vs_lab1.append([prediction, label])\n",
    "            if ensemble: pred_vs_lab2.append([prediction2, label])\n",
    "            if len(pred_vs_lab1) % eval_every == 0:\n",
    "                print(\"skipped eval\", len(pred_vs_lab1), \"times. (selective_guard)\")\n",
    "                if len(pred_vs_lab1) % (eval_every * 10) == 0:\n",
    "                    acc_1 = (pred_vs_lab1.count([0,0]) + pred_vs_lab1.count([1,1])) / len(pred_vs_lab1)\n",
    "                    print(\"(filtered out):\", round(acc_1, 4), \"(\", len(pred_vs_lab1), \")\")\n",
    "                    if ensemble:\n",
    "                        acc_2 = (pred_vs_lab2.count([0,0]) + pred_vs_lab2.count([1,1])) / len(pred_vs_lab2)\n",
    "                        print(\"(filtered2):\", round(acc_2, 4), \"(\", len(pred_vs_lab2), \")\")\n",
    "                        \n",
    "    del sequence_batch, label_batch, outputs, loss\n",
    "    if ensemble:\n",
    "        del outputs2, loss2\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Results (Train) '''\n",
    "# Final print to console\n",
    "accuracy_2nd_half = (predictions_vs_labels[-len(predictions_vs_labels)//2:].count([0,0]) + \n",
    "                      predictions_vs_labels[-len(predictions_vs_labels)//2:].count([1,1])) / (len(predictions_vs_labels)//2)\n",
    "accuracy_4th_q = (predictions_vs_labels[-len(predictions_vs_labels)//4:].count([0,0]) + \n",
    "                      predictions_vs_labels[-len(predictions_vs_labels)//4:].count([1,1])) / (len(predictions_vs_labels)//4)\n",
    "tp = predictions_vs_labels.count([1,1])\n",
    "tn = predictions_vs_labels.count([0,0])\n",
    "fp = predictions_vs_labels.count([1,0])\n",
    "fn = predictions_vs_labels.count([0,1])\n",
    "accuracy = (tp + tn) / len(predictions_vs_labels)\n",
    "print(\"LOOCV accuracy:\", round(accuracy,4), \"(\", len(predictions_vs_labels), \")\")\n",
    "print(\"accuracy_2nd_half:\", round(accuracy_2nd_half,4))\n",
    "print(\"accuracy_4th_q:\", round(accuracy_4th_q,4))\n",
    "print(\"tn, fp:\", tn, fp)\n",
    "print(\"fn, tp:\", fn, tp)\n",
    "precision = tp / (tp+fp)\n",
    "print(\"Precision (how precise model's prediction of 1 is):\", round(precision,4))\n",
    "recall = tp / (tp+fn)  # \"accuracy 1 only\"\n",
    "print(\"Recall (accuracy 1 only):\", round(recall,4))\n",
    "f1 = 2 * (precision*recall) / (precision+recall)\n",
    "print(\"F1 Score:\", round(f1,4))\n",
    "plt.gca().set_ylim([0,1])  # ax = plt.gca()\n",
    "plt.grid()\n",
    "plt.plot(loocv)\n",
    "plt.show()\n",
    "\n",
    "# Filtered predictions\n",
    "if pred_vs_lab1:\n",
    "    print(\"Performance on predictions that were filtered out: (selective_guard)\")\n",
    "    tp1 = pred_vs_lab1.count([1,1])\n",
    "    tn1 = pred_vs_lab1.count([0,0])\n",
    "    fp1 = pred_vs_lab1.count([1,0])\n",
    "    fn1 = pred_vs_lab1.count([0,1])\n",
    "    print(\"tn, fp:\", tn1, fp1)\n",
    "    print(\"fn, tp:\", fn1, tp1)\n",
    "    acc_1 = (tp1 + tn1) / len(pred_vs_lab1)\n",
    "    print(acc_1, \"(\", len(pred_vs_lab1), \")\")\n",
    "    if ensemble:\n",
    "        acc_2 = (pred_vs_lab2.count([0,0]) + pred_vs_lab2.count([1,1])) / len(pred_vs_lab2)\n",
    "        print(\"model2:\", acc_2, \"(\", len(pred_vs_lab2), \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test (Separate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_vs_labels = []\n",
    "plot_test = []\n",
    "for sequence, label in zip(test_data, test_labels):\n",
    "    hidden_state = None\n",
    "    hidden_state2 = None\n",
    "    sequence = torch.from_numpy(sequence).float().view(sequence_len, 1, input_size).to(device)\n",
    "    # label = torch.from_numpy(label).long().to(device)\n",
    "    \n",
    "    prediction, hidden_state = model(sequence, hidden_state)\n",
    "    prediction = list(prediction.data.squeeze())\n",
    "    max_prediction = float(max(prediction))\n",
    "    prediction = prediction.index(max(prediction))\n",
    "    # print(\"prediction:\", prediction)\n",
    "    if ensemble:\n",
    "        prediction2, hidden_state2 = model2(sequence[-short_sequence_len:], hidden_state2)\n",
    "        prediction2 = list(prediction2.data.squeeze())\n",
    "        max_prediction2 = float(max(prediction2))\n",
    "        prediction2 = prediction2.index(max(prediction2))\n",
    "        \n",
    "    # plot price sequence\n",
    "    plt.plot(sequence[:, :, -1].cpu())  # -1: close_price\n",
    "    # plt.show()\n",
    "    # plot other features\n",
    "    plt.subplot(1,1,1)\n",
    "    plt.plot(sequence[:, :, 5].cpu())\n",
    "    plt.show()\n",
    "    \n",
    "    test_predictions_vs_labels.append([prediction, label])\n",
    "    if len(test_predictions_vs_labels) % eval_every == 0:\n",
    "        accuracy = (test_predictions_vs_labels.count([0,0]) \n",
    "                    + test_predictions_vs_labels.count([1,1]) \n",
    "                    + test_predictions_vs_labels.count([0,-1])  # ... PRIVATE ... \n",
    "                    + test_predictions_vs_labels.count([1,-1])) / len(test_predictions_vs_labels)\n",
    "        accuracy_last_eval = (test_predictions_vs_labels[-eval_every:].count([0,0]) \n",
    "                            + test_predictions_vs_labels[-eval_every:].count([1,1]) \n",
    "                            + test_predictions_vs_labels[-eval_every:].count([0,-1])  # ... PRIVATE ...\n",
    "                            + test_predictions_vs_labels[-eval_every:].count([1,-1])) / eval_every\n",
    "        print(\"accuracy:\", round(accuracy,4), \"(last\", eval_every, \":\", accuracy_last_eval, \")\")\n",
    "        plot_test.append(accuracy)\n",
    "    \n",
    "accuracy = (test_predictions_vs_labels.count([0,0]) \n",
    "            + test_predictions_vs_labels.count([1,1]) \n",
    "            + test_predictions_vs_labels.count([0,-1])  # ... PRIVATE ...\n",
    "            + test_predictions_vs_labels.count([1,-1])) / len(test_predictions_vs_labels)\n",
    "print(\"Test accuracy:\", round(accuracy,4), \"(\", len(test_predictions_vs_labels), \")\")\n",
    "accuracy = (test_predictions_vs_labels.count([0,0]) \n",
    "            + test_predictions_vs_labels.count([1,1])) / (len(test_labels) - np.count_nonzero(test_labels==-1))\n",
    "print(\"accuracy (class only):\", round(accuracy,4))\n",
    "\n",
    "# del test_data, test_labels\n",
    "# ax = plt.gca()\n",
    "plt.gca().set_ylim([0,1])\n",
    "plt.grid()\n",
    "plt.plot(plot_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
