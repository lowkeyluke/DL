# DL
To put on record some fundamental Deep Learning methods I've implemented

- DCGAN, SAGAN
  - spectral norm, self-attention, wasserstein loss, visualization of attention maps
- (Multivariate) Time-series Classification (for Anomaly detection, & Prediction)
  - LSTM
  - LSTM-FCN
  - Ensemble models/methods
  - EDA: self-defined classes/labels, self-engineered features, feature visualization, hyperparameter tuning methods, etc.
  - "Live" training & testing simulation

(as well as more general Machine Learning concepts)
- Expectation (Variance, Std. Dev., etc.) & Estimation (MLE, MAP, EM)
- Inference & Conditional Probability: Bayes
- Optimization & Objective Functions
- Classification & Regression
  - Gaussian discriminators: LDA, QDA
  - Linear Regression, Non-linear Regression, & Ridge Regression
  - (Binary) Logistic Regression, Multi-class Logistic Regression
- Misc. Topics: Feature Selection + Engineering, ID3, SVM, LOOCV, Unsupervised Learning (K-means clustering, etc.)
- Practical Application
  - Data Preprocessing
  - Feedforward (+ activation functions) & Backpropagation (+ more optimization techniques / objective functions)
  - NN Architectures
    - "Vanilla" Deep dense/fully-connected Net
    - CNN (for classification)
    - GAN
    - RNN

(to be updated)
